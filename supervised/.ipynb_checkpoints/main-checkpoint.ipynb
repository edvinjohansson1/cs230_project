{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ebcbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "\tdev_sample_percentage: 0.05\n",
      "\tdata_file: /home/ubuntu/cs230_project/data/amazon_reviews_us_Electronics_v1_00.tsv\n",
      "\tword2vec_file: /home/ubuntu/cs230_project/data/glove.6B.100d.txt\n",
      "\tmin_total_votes: 10\n",
      "\tmax_review_word_count: 200\n",
      "\tkeep_start_of_longer_reviews: True\n",
      "\tbatch_size: 64\n",
      "\tnum_epochs: 20\n",
      "\tdebug_mode: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "# Configure keras backend to run on CPU\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "import argparse\n",
    "\n",
    "from utils import *\n",
    "from parameters import FLAGS\n",
    "from preprocessing import review_to_indices, embedding_layer_glove\n",
    "\n",
    "from models.uni_2_LSTM import Uni_2_LSTM\n",
    "from models.bi_2_LSTM import Bi_2_LSTM\n",
    "from models.cnn import CNN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98ab44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data ...\n",
      "Chunk loaded. Found 136128 data points with >= 10 total votes.\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_data(FLAGS.data_file,\n",
    "                 FLAGS.min_total_votes,\n",
    "                 FLAGS.max_review_word_count,\n",
    "                 FLAGS.keep_start_of_longer_reviews)\n",
    "\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(X, Y, test_size=FLAGS.dev_sample_percentage, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "916d4d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Examples in X_train: {X_train.shape[0]}')\n",
    "# print(f'Examples in X_dev:   {X_dev.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0576b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(3):\n",
    "#     print(X_train[idx], '\\n', Y_train[idx])\n",
    "#     print('\\n\\n')\n",
    "\n",
    "# print('#'*50, '\\n\\n')\n",
    "\n",
    "# for idx in range(3):\n",
    "#     print(X_dev[idx], '\\n', Y_dev[idx])\n",
    "#     print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d252d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating word embeddings matrix ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs(FLAGS.word2vec_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4828ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "# X1_indices = review_to_indices(X1, word_to_index, max_review_word_count=5)\n",
    "# print(\"X1 =\", X1)\n",
    "# print(\"X1_indices =\\n\", X1_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49304054",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"uni_2_LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 256, 100)          40000100  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256, 64)           34048     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 40,100,325\n",
      "Trainable params: 100,225\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Bi_2_LSTM((FLAGS.max_review_word_count, ),\n",
    "                   word_to_vec_map,\n",
    "                   word_to_index,\n",
    "                   lstm_units=[32, 64])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0353412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Conv2D, ReLU, MaxPooling2D, Reshape, Flatten\n",
    "\n",
    "from preprocessing import embedding_layer_glove\n",
    "\n",
    "\n",
    "def CNN1(input_shape, word_to_vec_map, word_to_index, FLAGS):\n",
    "    \"\"\"\n",
    "    Implements a two-layer unidirectional LSTM with dropout after each\n",
    "    LSTM layer as a Keras model object.\n",
    "    \n",
    "    Inputs:\n",
    "        input_shape:     shape of input review, put it as (FLAGS.max_review_word_count, )\n",
    "        word_to_vec_map: dictionary mapping from word to 100-dim vector embedding\n",
    "        word_to_index:   dictionary mapping from word to index in vocabulary\n",
    "        FLAGS:           hyperparameter settings\n",
    "    \n",
    "    Outputs:\n",
    "        model: A keras model object\n",
    "    \"\"\"\n",
    "    # b = batch_size\n",
    "    # e = embedding_dim = 100\n",
    "    \n",
    "    # Input layer\n",
    "    word_indices = Input(shape=input_shape, dtype='int32')                                        # (b, 200)\n",
    "    \n",
    "    # Embedding layer (pretrained with GloVe-100)\n",
    "    embeddings = embedding_layer_glove(word_to_vec_map, word_to_index)(word_indices)              # (b, 200, 100)\n",
    "    # Add 'channel' dimension of 1\n",
    "    embeddings_w_channels = Reshape((embeddings.shape[1], embeddings.shape[2], 1))(embeddings)    # (b, 200, 100, 1)\n",
    "\n",
    "    \n",
    "    ########### CNN part (start) #######################\n",
    "    Z1 = Conv2D(filters=8, kernel_size=(3, 3), strides=1, padding='valid')(embeddings_w_channels) # (b, 198, 98,  8)\n",
    "    print('Z1.shape', Z1.shape)\n",
    "    A1 = ReLU()(Z1)                                                                               # (b, 198, 98,  8)\n",
    "    print('A1.shape', A1.shape)\n",
    "    P1 = MaxPooling2D(pool_size=(2, 3), strides=(2, 3), padding='same')(A1)                       # (b,  99, 33,  8)\n",
    "    print('P1.shape', P1.shape, '\\n')\n",
    "    \n",
    "    Z2 = Conv2D(filters=16, kernel_size=(3, 3), strides=1, padding='valid')(P1)                   # (b,  97, 31, 16)\n",
    "    print('Z2.shape', Z2.shape)\n",
    "    A2 = ReLU()(Z2)                                                                               # (b,  97, 31, 16)\n",
    "    print('A2.shape', A2.shape)\n",
    "    P2 = MaxPooling2D(pool_size=(2, 3), strides=(2, 3), padding='same')(A2)                       # (b,  49, 11, 16)\n",
    "    print('P2.shape', P2.shape, '\\n')\n",
    "    \n",
    "    Z3 = Conv2D(filters=32, kernel_size=(5, 5), strides=1, padding='valid')(P2)                   # (b,  45,  7, 32)\n",
    "    print('Z3.shape', Z3.shape)\n",
    "    A3 = ReLU()(Z3)                                                                               # (b,  45,  7, 32)\n",
    "    print('A3.shape', A3.shape)\n",
    "    P3 = MaxPooling2D(pool_size=(2, 3), strides=(2, 3), padding='same')(A3)                       # (b,  23,  3, 32)\n",
    "    print('P3.shape', P3.shape, '\\n')   \n",
    "    ########### CNN part (end) #######################\n",
    "    \n",
    "    F = Flatten()(P3)\n",
    "    print('F.shape', F.shape)                                                                     # (b, 2208)\n",
    "    out = Dense(units=1)(F)\n",
    "    print('out.shape', out.shape)                                                                 # (b, 1)\n",
    "    \n",
    "    \n",
    "    # Finally, create the model object\n",
    "    model = Model(inputs=word_indices, outputs=out, name='CNN1')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f500ce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z1.shape (None, 198, 98, 8)\n",
      "A1.shape (None, 198, 98, 8)\n",
      "P1.shape (None, 99, 33, 8) \n",
      "\n",
      "Z2.shape (None, 97, 31, 16)\n",
      "A2.shape (None, 97, 31, 16)\n",
      "P2.shape (None, 49, 11, 16) \n",
      "\n",
      "Z3.shape (None, 45, 7, 32)\n",
      "A3.shape (None, 45, 7, 32)\n",
      "P3.shape (None, 23, 3, 32) \n",
      "\n",
      "F.shape (None, 2208)\n",
      "out.shape (None, 1)\n",
      "Model: \"CNN1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 200, 100)          40000100  \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 200, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 198, 98, 8)        80        \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 198, 98, 8)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 99, 33, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 97, 31, 16)        1168      \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 97, 31, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 49, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 45, 7, 32)         12832     \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 45, 7, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 23, 3, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2208)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2209      \n",
      "=================================================================\n",
      "Total params: 40,016,389\n",
      "Trainable params: 16,289\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CNN1((FLAGS.max_review_word_count, ),\n",
    "              word_to_vec_map,\n",
    "              word_to_index,\n",
    "              FLAGS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f433d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist([len(X_train[i].split(' ')) for i in range(X_train.shape[0])], bins=40)\n",
    "# plt.xlim([0, 1000])\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(Y_train, bins=100)\n",
    "# plt.xlim([0, 1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52ac2f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9992f61",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1474/2021 [====================>.........] - ETA: 3:02 - loss: 0.0602 - mse: 0.0602"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-359fd537bcea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_dev_indices\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mreview_to_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mword_to_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_review_word_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train_indices = review_to_indices(X_train, word_to_index, FLAGS.max_review_word_count)\n",
    "X_dev_indices   = review_to_indices(X_dev,   word_to_index, FLAGS.max_review_word_count)\n",
    "\n",
    "model.fit(X_train_indices, Y_train, epochs=FLAGS.num_epochs, batch_size=FLAGS.batch_size, shuffle=True,\n",
    "          validation_data=(X_dev_indices, Y_dev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
